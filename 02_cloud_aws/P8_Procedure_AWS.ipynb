{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f0f7c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Déploiement de la solution sur le cloud\n",
    "\n",
    "Maintenant que nous avons vérifié que notre solution fonctionne, <br />\n",
    "il est temps de la <u>déployer à plus grande échelle sur un vrai cluster de machines</u>.\n",
    "\n",
    "**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\n",
    "les commandes décrites ci-dessous sont donc réalisées <br />\n",
    "exclusivement dans cet environnement.*\n",
    "\n",
    "<u>Plusieurs contraintes se posent</u> :\n",
    " 1. Quel prestataire de Cloud choisir ?\n",
    " 2. Quelles solutions de ce prestataire adopter ?\n",
    " 3. Où stocker nos données ?\n",
    " 4. Comment configurer nos outils dans ce nouvel environnement ?\n",
    " \n",
    "## 1.1 Choix du prestataire cloud : AWS\n",
    "\n",
    "Le prestataire le plus connu et qui offre à ce jour l'offre <br />\n",
    "la plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\n",
    "Certaines de leurs offres sont parfaitement adaptées à notre problématique <br />\n",
    "et c'est la raison pour laquelle j'utiliserai leurs services.\n",
    "\n",
    "L'objectif premier est de pouvoir, grâce à AWS, <u>louer de la puissance de calcul à la demande</u>. <br />\n",
    "L'idée étant de pouvoir, quel que soit la charge de travail, <br />\n",
    "obtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\n",
    "même si le volume de données venait à fortement augmenter.\n",
    "\n",
    "De plus, la capacité d'utiliser cette puissance de calcul à la demande <br />\n",
    "permet de diminuer drastiquement les coûts si l'on compare les coûts d'une location <br />\n",
    "de serveur complet sur une durée fixe (1 mois, 1 année par exemple).\n",
    "\n",
    "## 1.2 Choix de la solution technique : EMR\n",
    "\n",
    "<u>Plusieurs solutions s'offre à nous</u> :\n",
    "1. Solution **IAAS** (Infrastructure AS A Service)\n",
    " - Dans cette configuration **AWS** met à notre disposition des serveurs vierges <br />\n",
    "   sur lequel nous avons un accès en administrateur, ils sont nommés **instance EC2**.<br />\n",
    "   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n",
    "   à l'identique la solution mis en œuvre en local sur notre machine.<br />\n",
    "   <u>On installe nous-même l'intégralité des outils puis on exécute notre script</u> :\n",
    "  - Installation de **Spark**, **Java** etc.\n",
    "  - Installation de **Python** (via Anaconda par exemple)\n",
    "  - Installation de **Jupyter Notebook**\n",
    "  - Installation des **librairies complémentaires**\n",
    "  - Il faudra bien évidement veiller à **implémenter les librairies \n",
    "    nécessaires à toutes les machines (workers) du cluster**\n",
    "  - <u>Avantages</u> :\n",
    "      - Liberté totale de mise en œuvre de la solution\n",
    "      - Facilité de mise en œuvre à partir d'un modèle qui s'exécute en local sur une machine Linux\n",
    "  - <u>Inconvénients</u> :\n",
    "      - Cronophage\n",
    "          - Nécessité d'installer et de configurer toute la solution\n",
    "      - Possible problèmes techniques à l'installation des outils (des problématiques qui <br />\n",
    "        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n",
    "      - Solution non pérenne dans le temps, il faudra veiller à la mise à jour des outils <br />\n",
    "        et éventuellement devoir réinstaller Spark, Java etc. \n",
    "2. Solution **PAAS** (Plateforme As A Service)\n",
    " - **AWS** fournit énormément de services différents, dans l'un de ceux-là <br />\n",
    "   il existe une offre qui permet de louer des **instances EC2** <br />\n",
    "   avec des applications préinstallées et configurées : il s'agit du **service EMR**.\n",
    " - **Spark** y sera déjà installé\n",
    " - Possibilité de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n",
    " - Possibilité d'indiquer des **packages complémentaires** à installer <br />\n",
    "   à l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n",
    " - <u>Avantages</u> :\n",
    "     - Facilité de mise en œuvre\n",
    "         - Il suffit de très peu de configuration pour obtenir <br />\n",
    "           un environnement parfaitement fonctionnel\n",
    "     - Rapidité de mise en œuvre\n",
    "         - Une fois la première configuration réalisée, il est très facile <br />\n",
    "           et très rapide de recréer des clusters à l'identique qui seront <br />\n",
    "           disponibles presque instantanément (le temps d'instancier les <br />\n",
    "           serveurs soit environ 15/20 minutes)\n",
    "     - Solutions matérielles et logicielles optimisées par les ingénieurs d'AWS\n",
    "         - On sait que les versions installées vont fonctionner <br />\n",
    "           et que l'architecture proposée est optimisée\n",
    "     - Stabilité de la solution\n",
    "    - Solution évolutive\n",
    "        Il est facile d’obtenir à chaque nouvelle instanciation une version à jour <br />\n",
    "        de chaque package, en étant garanti de leur compatibilité avec le reste de l’environnement.\n",
    "  - Plus sécurisé\n",
    "\t- Les éventuels patchs de sécurité seront automatiquement mis à jour <br />\n",
    "      à chaque nouvelle instanciation du cluster EMR.\n",
    " - <u>Inconvénients</u> :\n",
    "     - Peut-être un certain manque de liberté sur la version des packages disponibles ? <br />\n",
    "       Même si je n'ai pas constaté ce problème.\n",
    "   \n",
    "\n",
    "Je retiens la solution **PAAS** en choisissant d'utiliser <br />\n",
    "le service **EMR** d'Amazon Web Services.<br />\n",
    "Je la trouve plus adaptée à notre problématique et permet <br />\n",
    "une mise en œuvre qui soit à la fois plus rapide et <br />\n",
    "plus efficace que la solution IAAS.\n",
    "\n",
    "## 1.3 Choix de la solution de stockage des données : Amazon S3\n",
    "\n",
    "<u>Amazon propose une solution très efficace pour la gestion du stockage des données</u> : **Amazon S3**. <br />\n",
    "S3 pour Amazon Simple Storage Service.\n",
    "\n",
    "Il pourrait être tentant de stocker nos données sur l'espace alloué par le serveur **EC2**, <br />\n",
    "mais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n",
    "<u>les données seront perdues</u> lorsque le serveur sera résilié (on résilie le serveur lorsqu'on <br />\n",
    "ne s'en sert pas pour des raisons de coût).<br />\n",
    "De fait, si l'on décide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\n",
    "une solution pour sauvegarder les données avant la résiliation du serveur.\n",
    "De plus, nous serions exposés à certaines problématiques si nos données venaient à <br />\n",
    "**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n",
    "\n",
    "<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces problématiques</u>. <br />\n",
    "L'espace disque disponible est **illimité**, et il est **indépendant de nos serveurs EC2**. <br />\n",
    "L'accès aux données est **très rapide** car nous restons dans l'environnement d'AWS <br />\n",
    "et nous prenons soin de <u>choisir la même région pour nos serveurs **EC2** et **S3**</u>.\n",
    "\n",
    "De plus, comme nous le verrons <u>il est possible d'accéder aux données sur **S3** <br />\n",
    "    de la même manière que l'on **accède aux données sur un disque local**</u>.<br />\n",
    "Nous utiliserons simplement un **PATH au format s3://...** .\n",
    "\n",
    "## 1.4 Configuration de l'environnement de travail\n",
    "\n",
    "La première étape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\n",
    "il s'agit de l'**interface en ligne de commande d'AWS**.<br />\n",
    "Elle nous permet d'**interagir avec les différents services d'AWS**, comme **S3** par exemple.\n",
    "\n",
    "Pour pouvoir utiliser **AWS Cli**, il faut le configurer en créant préalablement <br />\n",
    "un utilisateur à qui on donnera les autorisations dont nous aurons besoin.<br />\n",
    "Dans ce projet il faut que l'utilisateur ait à minima un contrôle total sur le service S3.\n",
    "\n",
    "<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **AMI**</u> d'AWS.\n",
    "\n",
    "Une fois l'utilisateur créé et ses autorisations configurées nous créons une **paire de clés** <br />\n",
    "qui nous permettra de nous **connecter sans à avoir à devoir saisir systématiquement notre login/mot de passe**.<br />\n",
    "\n",
    "Il faut également configurer l'**accès SSH** à nos futurs serveurs EC2. <br />\n",
    "Ici aussi, via un système de clés qui nous dispense de devoir nous authentifier \"à la main\" à chaque connexion.\n",
    "\n",
    "Toutes ses étapes de configuration sont parfaitement décrites <br />\n",
    "dans le cours du projet: [Réalisez des calculs distribués sur des données massives / Découvrez Amazon Web Services](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308686-decouvrez-amazon-web-services#/id/r-4355822)\n",
    "\n",
    "## 1.5 Upload de nos données sur S3\n",
    "\n",
    "Nos outils sont configurés. <br />\n",
    "Il faut maintenant uploader nos données de travail sur Amazon S3.\n",
    "\n",
    "Ici aussi les étapes sont décrites avec précision <br />\n",
    "dans le cours [Réalisez des calculs distribués sur des données massives / Stockez des données sur S3](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308691-stockez-des-donnees-sur-s3)\n",
    "\n",
    "Je décide de n'uploader que les données contenues dans le dossier **Test** du [jeu de données du projet](https://www.kaggle.com/moltean/fruits/download)\n",
    "\n",
    "\n",
    "La première étape consiste à **créer un bucket sur S3** <br />\n",
    "dans lequel nous uploaderons les données du projet:\n",
    "- **aws s3 mb s3://p8-data**\n",
    "\n",
    "On vérifie que le bucket à bien été créé\n",
    "- **aws s3 ls**\n",
    " - Si le nom du bucket s'affiche alors c'est qu'il a été correctement créé.\n",
    "\n",
    "On copie ensuite le contenu du dossier \"**Test**\" <br />\n",
    "dans un répertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n",
    "1. On se place à l'intérieur du répertoire **Test**\n",
    "2. **aws sync . s3://p8-data/Test**\n",
    "\n",
    "La commande **sync** est utile pour synchroniser deux répertoires.\n",
    "\n",
    "<u>Nos données du projet sont maintenant disponibles sur Amazon S3</u>.\n",
    "\n",
    "## 1.6 Configuration du serveur EMR\n",
    "\n",
    "Une fois encore, le cours [Réalisez des calculs distribués sur des données massives / Déployez un cluster de calculs distribués](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues) <br /> détaille l'essentiel des étapes pour lancer un cluster avec **EMR**.\n",
    "\n",
    "<u>Je détaillerai ici les étapes particulières qui nous permettent <br />\n",
    "de configurer le serveur selon nos besoins</u> :\n",
    "\n",
    "1. Cliquez sur Créer un cluster\n",
    "![Créer un cluster](img/EMR_creer.png)\n",
    "2. Cliquez sur Accéder aux options avancées\n",
    "![Créer un cluster](img/EMR_options_avancees.png)\n",
    "\n",
    "### 1.6.1 Étape 1 : Logiciels et étapes\n",
    "\n",
    "#### 1.6.1.1 Configuration des logiciels\n",
    "\n",
    "<u>Sélectionnez les packages dont nous aurons besoin comme dans la capture d'écran</u> :\n",
    "1. Nous sélectionnons la dernière version d'**EMR**, soit la version **6.3.0** au moment où je rédige ce document\n",
    "2. Nous cochons bien évidement **Hadoop** et **Spark** qui seront préinstallés dans leur version la plus récente\n",
    "3. Nous aurons également besoin de **TensorFlow** pour importer notre modèle et réaliser le **transfert learning**\n",
    "4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n",
    " - Comme nous le verrons dans un instant nous allons <u>paramétrer l'application afin que les notebooks</u>, <br />\n",
    "   comme le reste de nos données de travail, <u>soient enregistrés directement sur S3</u>.\n",
    "![Créer un cluster](img/EMR_configuration_logiciels.png)\n",
    "\n",
    "#### 1.6.1.2 Modifier les paramètres du logiciel\n",
    "\n",
    "<u>Paramétrez la persistance des notebooks créés et ouvert via JupyterHub</u> :\n",
    "- On peut à cette étape effectuer des demandes de paramétrage particulières sur nos applications. <br />\n",
    "  L'objectif est, comme pour le reste de nos données de travail, <br />\n",
    "  d'éviter toutes les problématiques évoquées précédemment. <br />\n",
    "  C'est l'objectif à cette étape, <u>nous allons enregistrer <br />\n",
    "  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n",
    "  ce serait le cas dans la configuration par défaut de JupyterHub) mais <br />\n",
    "  <u>directement sur **Amazon S3**</u>.\n",
    "- <u>deux solutions sont possibles pour réaliser cela</u> :\n",
    " 1. Créer un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d’accès au fichier JSON\n",
    " 2. Rentrez directement la configuration au format JSON\n",
    " \n",
    "J'ai personnellement créé un fichier JSON lors de la création de ma première instance EMR, <br />\n",
    "puis lorsqu'on décide de cloner notre serveur pour en recréer un facilement à l'identique, <br />\n",
    "la configuration du fichier JSON se retrouve directement copié comme dans la capture ci-dessous.\n",
    "\n",
    "<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n",
    " Appuyez ensuite sur \"**Suivant**\"\n",
    "![Modifier les paramètres du logiciel](img/EMR_parametres_logiciel.png)\n",
    "\n",
    "### 1.6.2 Étape 2 : Matériel\n",
    "\n",
    "A cette étape, laissez les choix par défaut. <br />\n",
    "<u>L'important ici est la sélection de nos instances</u> :\n",
    "\n",
    "1. je choisi les instances de type **M5** qui sont des **instances de type équilibrés**\n",
    "2. je choisi le type **xlarge** qui est l'instance la **moins onéreuse disponible**\n",
    " [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n",
    "3. Je sélectionne **1 instance Maître** (le driver) et **2 instances Principales** (les workeurs) <br />\n",
    "   soit **un total de 3 instance EC2**.\n",
    "![Choix du materiel](img/EMR_materiel.png)\n",
    "\n",
    "### 1.6.3 Étape 3 : Paramètres de cluster généraux\n",
    "\n",
    "#### 1.6.3.1 Options générales\n",
    "<u>La première chose à faire est de donner un nom au cluster</u> :<br />\n",
    "*J'ai également décoché \"Protection de la résiliation\" pour des raisons pratiques.*\n",
    "    \n",
    "![Nom du Cluster](img/EMR_nom_cluster.png)\n",
    "\n",
    "#### 1.6.3.2 Actions d'amorçage\n",
    "\n",
    "Nous allons à cette étape **choisir les packages manquants à installer** et qui <br />\n",
    "nous serons utiles dans l'exécution de notre notebook.<br />\n",
    "<u>L'avantage de réaliser cette étape maintenant est que les packages <br />\n",
    "installés le seront sur l'ensemble des machines du cluster</u>.\n",
    "\n",
    "La procédure pour créer le fichier **bootstrap** qui contient <br />\n",
    "l'ensemble des instructions permettant d'installer tous <br />\n",
    "les packages dont nous aurons besoin est expliqué dans <br />\n",
    "le cours [Réalisez des calculs distribués sur des données massives / Bootstrapping](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356490)\n",
    "\n",
    "Nous créons donc un fichier nommé \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\n",
    "sur S3</u>(je l’installe à la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\n",
    "comme indiqué dans la capture d'écran ci-dessous:\n",
    "![Actions d'amorcage](img/EMR_amorcage.png)\n",
    "\n",
    "Voici le contenu du fichier **bootstrap-emr.sh**<br />\n",
    "Comme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\n",
    "pour **installer les bibliothèques manquantes** comme réalisé en local.<br />\n",
    "Une fois encore, <u>il est nécessaire de réaliser ces actions à cette étape</u> <br />\n",
    "pour que <u>les packages soient installés sur l'ensemble des machines du cluster</u> <br />\n",
    "et non pas uniquement sur le driver, comme cela serait le cas si nous exécutions <br />\n",
    "ces commandes directement dans le notebook JupyterHub ou dans la console EMR (connecté au driver).\n",
    "![Contenu du fichier bootstrap](img/EMR_bootstrap.png)\n",
    "\n",
    "**setuptools** et **pip** sont mis à jour pour éviter une problématique <br />\n",
    "avec l'installation du package **pyarrow**.<br />\n",
    "**Pandas** a eu droit à une mise à jour majeur (1.3.0) il y a moins d'une semaine <br />\n",
    "au moment de la rédaction de ce notebook, et la nouvelle version de **Pandas** <br />\n",
    "nécessite une version plus récente de **Numpy** que la version installée par <br />\n",
    "défaut (1.16.5) à l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\n",
    "possible d'imposer une autre version de Numpy que celle installé par <br />\n",
    "défaut</u> même si on force l'installation d'une version récente de **Numpy** <br />\n",
    "(en tout cas, ni simplement ni intuitivement).<br />\n",
    "La mise à jour étant très récente <u>la version de **Numpy** n'est pas encore <br />\n",
    "mise à jour sur **EC2**</u> mais on peut imaginer que ce sera le cas très rapidement <br />\n",
    "et il ne sera plus nécessaire d'imposer une version spécifique de **Pandas**.<br />\n",
    "En attendant, je demande <u>l'installation de l'avant dernière version de **Pandas (1.2.5)**</u>\n",
    "\n",
    "On clique ensuite sur ***Suivant***\n",
    "\n",
    "### 1.6.4 Étape 4 : Sécurité\n",
    "\n",
    "#### 1.6.4.1 Options de sécurité\n",
    "\n",
    "A cette étape nous sélectionnons la **paire de clés EC2** créé précédemment. <br />\n",
    "Elle nous permettra de se connecter en **ssh** à nos **instances EC2** <br />\n",
    "sans avoir à entrer nos login/mot de passe.<br />\n",
    "On laisse les autres paramètres par défaut. <br />\n",
    "Et enfin, on clique sur \"***Créer un cluster***\"\n",
    " \n",
    "![EMR Sécurité](img/EMR_securite.png)\n",
    "\n",
    "## 1.7 Instanciation du serveur\n",
    "\n",
    "Il ne nous reste plus qu'à attendre que le serveur soit prêt. <br />\n",
    "Cette étape peut prendre entre **15 et 20 minutes**.\n",
    "\n",
    "<u>Plusieurs étapes s'enchaîne, on peut suivre l'avancé du statut du **cluster EMR**</u> :\n",
    "\n",
    "![Instanciation étape 1](img/EMR_instanciation_01.png)\n",
    "![Instanciation étape 2](img/EMR_instanciation_02.png)\n",
    "![Instanciation étape 3](img/EMR_instanciation_03.png)\n",
    "\n",
    "<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\n",
    "s'est bien déroulée et que notre serveur est prêt à être utilisé</u>. \n",
    "\n",
    "## 1.8 Création du tunnel SSH à l'instance EC2 (Maître)\n",
    "\n",
    "### 1.8.1 Création des autorisations sur les connexions entrantes\n",
    "\n",
    "<u>Nous souhaitons maintenant pouvoir accéder à nos applications</u> :\n",
    " - **JupyterHub** pour l'exécution de notre notebook\n",
    " - **Serveur d'historique Spark** pour le suivi de l'exécution <br />\n",
    "   des tâches de notre script lorsqu'il sera lancé\n",
    " \n",
    "Cependant, <u>ces applications ne sont accessibles que depuis le réseau local du driver</u>, <br />\n",
    "et pour y accéder nous devons **créer un tunnel SSH vers le driver**.\n",
    "\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "<u>Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le **groupe de sécurité EC2 du driver**</u>.\n",
    "\n",
    "Cette étape est décrite dans le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356512): \n",
    "\n",
    "*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le groupe de sécurité EC2 du driver. Sur la page de la console <br />\n",
    "consacrée à EC2, dans l'onglet \"Réseau et sécurité\", cliquez sur \"Groupes de sécurité\". <br />\n",
    "Vous allez devoir modifier le groupe de sécurité d’ElasticMapReduce-Master. <br />\n",
    "Dans l'onglet \"Entrant\", ajoutez une règle SSH dont la source est \"N'importe où\" <br />\n",
    "(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n",
    "\n",
    "![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n",
    "\n",
    "<u>Une fois cette étape réalisée vous devriez avoir une configuration semblable à la mienne</u> :\n",
    "\n",
    "![Configuration ssh terminée](img/EMR_config_ssh_02.png)\n",
    "\n",
    "### 1.8.2 Création du tunnel ssh vers le Driver\n",
    "\n",
    "On peut maintenant établir le **tunnel SSH** vers le **Driver**. <br />\n",
    "Pour cela on récupère les informations de connexion fournis par Amazon <br />\n",
    "depuis la page du service EMR / Cluster / onglet Récapitulatif en <br />\n",
    "cliquant sur \"**Activer la connexion Web**\"\n",
    "\n",
    "![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n",
    "\n",
    "<u>On récupère ensuite la commande fournis par Amazon pour **établir le tunnel SSH**</u> :\n",
    "\n",
    "![Récupérer la commande pour établir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n",
    "\n",
    "<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter à ma configuration**. <br />\n",
    "La **clé ssh** se situe dans un dossier \"**.ssh**\" elle-même située dans <br />\n",
    "mon **répertoire personnel** dont le symbole est, sous Linux, identifié par un tilde \"**~**\".\n",
    "\n",
    "Ayant suivi le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives) <br />\n",
    "j'ai choisi d'utiliser le port **5555** au lieu du **8157**, même si le choix n'est pas très important.<br />\n",
    "    j'ai également rencontré un <u>problème de compatibilité</u> avec <br />\n",
    "l'argument \"**-N**\" (liste des arguments et leur significations <br />\n",
    "disponibles [ici](https://explainshell.com/explain?cmd=ssh+-L+-N+-f+-l+-D)) j'ai décidé de simplement le supprimer.\n",
    "\n",
    "<u>Finalement, j'utilise la commande suivante dans un terminal pour établir <br />\n",
    "    mon tunnel ssh (seul l'URL change d'une instance à une autre)</u> : <br />\n",
    "\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n",
    "\n",
    "<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n",
    "    la connexion est établit on obtient le résultat suivant</u> :\n",
    "\n",
    "![Création du tunnel SSH](img/EMR_connexion_ssh_01.png)\n",
    "\n",
    "Nous avons **correctement établi le tunnel ssh avec le driver** sur le port \"5555\".\n",
    "\n",
    "### 1.8.3 Configuration de FoxyProxy\n",
    "\n",
    "Une dernière étape est nécessaire pour accéder à nos applications, <br />\n",
    "en demandant à notre navigateur d'emprunter le tunnel ssh.<br />\n",
    "J'utilise pour cela **FoxyProxy**.\n",
    "[Une fois encore, vous pouvez utiliser le cours pour le configurer](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308701-realisez-la-maintenance-dun-cluster#/id/r-4356554).\n",
    "\n",
    "Sinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut à gauche <br />\n",
    "puis renseigner les éléments comme dans la capture ci-dessous :\n",
    "\n",
    "![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n",
    "\n",
    "<u>On obtient le résultat ci-dessous</u> :\n",
    "\n",
    "![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n",
    "\n",
    "\n",
    "### 1.8.4 Accès aux applications du serveur EMR via le tunnel ssh\n",
    "\n",
    "\n",
    "<u>Avant d'établir notre **tunnel ssh** nous avions ça</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n",
    "\n",
    "<u>On active le **tunnel ssh** comme vu précédemment puis on demande <br />\n",
    "à notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n",
    "\n",
    "![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n",
    "\n",
    "<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n",
    "\n",
    "## 1.9 Connexion au notebook JupyterHub\n",
    "\n",
    "Pour se connecter à **JupyterHub** en vue d'exécuter notre **notebook**, <br />\n",
    "il faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\n",
    "depuis que nous avons configuré le **tunnel ssh** et **foxyproxy** sur <br />\n",
    "notre navigateur (actualisez la page si ce n’est pas le cas).\n",
    "\n",
    "![Démarrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n",
    "\n",
    "On passe les éventuels avertissements de sécurité puis <br />\n",
    "nous arrivons sur une page de connexion.\n",
    "    \n",
    "<u>On se connecte avec les informations par défaut</u> :\n",
    " - <u>login</u>: **jovyan**\n",
    " - <u>password</u>: **jupyter**\n",
    " \n",
    "![Connexion à JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n",
    "\n",
    "Nous arrivons ensuite dans un dossier vierge de notebook.<br />\n",
    "Il suffit d'en créer un en cliquant sur \"**New**\" en haut à droite.\n",
    "\n",
    "![Liste et création des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n",
    "\n",
    "Il est également possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n",
    "\n",
    "Grace à la <u>**persistance** paramétrée à l'instanciation du cluster <br />\n",
    "nous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n",
    "\n",
    "![Notebook stockés sur S3](img/EMR_jupyterhub_S3.png)\n",
    "\n",
    "Je décide d'**importer un notebook déjà rédigé en local directement <br />\n",
    "sur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n",
    "\n",
    "## 1.10 Exécution du code\n",
    "\n",
    "Je décide d'exécuter cette partie du code depuis **JupyterHub hébergé sur notre cluster EMR**.<br />\n",
    "Pour ne pas alourdir inutilement les explications du **notebook**, je ne réexpliquerai pas les étapes communes <br />\n",
    "que nous avons déjà vues dans la première partie où l'on a exécuté le code localement sur notre machine virtuelle Ubuntu.\n",
    "\n",
    "<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n",
    "\n",
    "**En utilisant ce kernel, une session spark est créé à l'exécution de la première cellule**. <br />\n",
    "Il n'est donc **plus nécessaire d'exécuter le code \"spark = (SparkSession ...\"** comme lors <br />\n",
    "de l'exécution de notre notebook en local sur notre VM Ubuntu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Execution of code in P8_Notebook_AWS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "72974aab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<u>On peut également constater la présence des fichiers <br />\n",
    "    au format \"**parquet**\" sur le **serveur S3**</u> :\n",
    "\n",
    "![Affichage des résultats sur S3](img/S3_Results.png)\n",
    "\n",
    "## 4.11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark\n",
    "\n",
    "Il est possible de voir l'avancement des tâches en cours <br />\n",
    "avec le **serveur d'historique Spark**.\n",
    "\n",
    "![Accès au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n",
    "\n",
    "**Il est également possible de revenir et d'étudier les tâches <br />\n",
    "qui ont été réalisé, afin de debugger, optimiser les futurs <br />\n",
    "tâches à réaliser.**\n",
    "\n",
    "<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n",
    "était en cours, nous pouvions observer son état d'avancement</u> :\n",
    "\n",
    "![Progression execution script](img/EMR_jupyterhub_avancement.png)\n",
    "\n",
    "<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus précise <br />\n",
    "de l'exécution des différentes tâche sur les différentes machines du cluster</u> :\n",
    "\n",
    "![Suivi des tâches spark](img/EMR_SHSpark_01.png)\n",
    "\n",
    "On peut également constater que notre cluster de calcul a mis <br />\n",
    "un tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n",
    "\n",
    "![Temps de traitement](img/EMR_SHSpark_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d65bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.12 Résiliation de l'instance EMR\n",
    "\n",
    "Notre travail est maintenant terminé. <br />\n",
    "Le cluster de machines EMR est **facturé à la demande**, <br />\n",
    "et nous continuons d'être facturé même lorsque <br />\n",
    "les machines sont au repos.<br />\n",
    "Pour **optimiser la facturation**, il nous faut <br />\n",
    "maintenant **résilier le cluster**.\n",
    "\n",
    "<u>Je réalise cette commande depuis l'interface AWS</u> :\n",
    "\n",
    "1. Commencez par **désactiver le tunnel ssh dans FoxyProxy** pour éviter des problèmes de **timeout**.\n",
    "![Désactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n",
    "2. Cliquez sur \"**Résilier**\"\n",
    "![Cliquez sur Résilier](img/EMR_resiliation_01.png)\n",
    "3. Confirmez la résiliation\n",
    "![Confirmez la résiliation](img/EMR_resiliation_02.png)\n",
    "4. La résiliation prend environ **1 minute**\n",
    "![Résiliation en cours](img/EMR_resiliation_03.png)\n",
    "5. La résiliation est effectuée\n",
    "![Résiliation terminée](img/EMR_resiliation_04.png)\n",
    "\n",
    "## 4.13 Cloner le serveur EMR (si besoin)\n",
    "\n",
    "Si nous devons de nouveau exécuter notre notebook dans les mêmes conditions, <br />\n",
    "il nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\n",
    "sous 15/20 minutes, le temps de son instanciation.\n",
    "\n",
    "<u>Pour cela deux solutions</u> :\n",
    "1. <u>Depuis l'interface AWS</u> :\n",
    " 1. Cliquez sur \"**Cloner**\"\n",
    "   ![Cloner un cluster](img/EMR_cloner_01.png)\n",
    " 2. Dans notre cas nous ne souhaitons pas inclure d'étapes\n",
    "   ![Ne pas inclure d'étapes](img/EMR_cloner_02.png)\n",
    " 3. La configuration du cluster est recréée à l’identique. <br />\n",
    "    On peut revenir sur les différentes étapes si on souhaite apporter des modifications<br />\n",
    "    Quand tout est prêt, cliquez sur \"**Créer un cluster**\"\n",
    "  ![Vérification/Modification/Créer un cluster](img/EMR_cloner_03.png)\n",
    "2. <u>En ligne de commande</u> (avec AWS CLI d'installé et de configuré et en s'assurant <br />\n",
    "   de s'attribuer les droits nécessaires sur le compte AMI utilisé)\n",
    " 1. Cliquez sur \"**Exporter AWS CLI**\"\n",
    " ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n",
    " 2. Copier/Coller la commande **depuis un terminal**\n",
    " ![Copier Coller Commande](img/EMR_cloner_cli_02.png)\n",
    "\n",
    "## 4.14 Arborescence du serveur S3 à la fin du projet\n",
    "\n",
    "<u>Pour information, voici **l'arborescence complète de mon bucket S3 p8-data** à la fin du projet</u> : <br />\n",
    "*Par soucis de lisibilité, je ne liste pas les 131 sous dossiers du répertoire \"Test\"*\n",
    "\n",
    "1. Results/_SUCCESS\n",
    "1. Results/part-00000-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00001-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00002-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00003-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00004-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00005-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00006-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00007-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00008-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00009-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00010-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00011-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00012-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00013-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00014-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00015-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00016-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00017-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00018-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00019-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00020-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00021-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00022-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00023-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Test/\n",
    "1. bootstrap-emr.sh\n",
    "1. jupyter-s3-conf.json\n",
    "1. jupyter/jovyan/.s3keep\n",
    "1. jupyter/jovyan/P8_01_Notebook.ipynb\n",
    "1. jupyter/jovyan/_metadata\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/file-perm.sqlite\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/html/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/latex/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbsignatures.db\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/notebook_secret\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/test3-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled1.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/test3.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}